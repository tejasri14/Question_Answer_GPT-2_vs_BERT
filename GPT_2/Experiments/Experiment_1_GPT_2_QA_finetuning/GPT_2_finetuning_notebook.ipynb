{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H7LoMj4GA4n_"
   },
   "source": [
    "## GPT-2 Fine Tuning Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kIrjW5wz53XH",
    "outputId": "d3e1a19d-9026-4659-c95d-8410f71c1ad0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KBkpRgBCBS2_"
   },
   "outputs": [],
   "source": [
    "!pip install -q gpt-2-simple\n",
    "import gpt_2_simple as gpt2\n",
    "from datetime import datetime\n",
    "from google.colab import files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kdvSie3L6mdf",
    "outputId": "c3600f65-29ea-40ae-ff07-1f882daa1c46"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.14.1)\n",
      "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.3)\n",
      "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.8.2)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.4.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.2.1)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n",
      "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.46)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.6)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.6.0)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bj2IJLHP3KwE"
   },
   "source": [
    "## GPU\n",
    "\n",
    "Colaboratory uses either a Nvidia T4 GPU or an Nvidia K80 GPU. The T4 is slightly faster than the old K80 for training GPT-2, and has more memory allowing you to train the larger GPT-2 models and generate more text.\n",
    "\n",
    "You can verify which GPU is active by running the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sUmTooTW3osf",
    "outputId": "7d00e98a-3bad-4591-a9e0-9943ae93cd08"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NVIDIA-SMI has failed because it couldn't communicate with the NVIDIA driver. Make sure that the latest NVIDIA driver is installed and running.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0wXB05bPDYxS"
   },
   "source": [
    "## Downloading GPT-2\n",
    "\n",
    "If you're retraining a model on new text, you need to download the GPT-2 model first. \n",
    "\n",
    "There are three released sizes of GPT-2:\n",
    "\n",
    "* `124M` (default): the \"small\" model, 500MB on disk.\n",
    "* `355M`: the \"medium\" model, 1.5GB on disk.\n",
    "* `774M`: the \"large\" model, cannot currently be finetuned with Colaboratory but can be used to generate text from the pretrained model (see later in Notebook)\n",
    "* `1558M`: the \"extra large\", true model. Will not work if a K80/P4 GPU is attached to the notebook. (like `774M`, it cannot be finetuned).\n",
    "\n",
    "Larger models have more knowledge, but take longer to finetune and longer to generate text. You can specify which base model to use by changing `model_name` in the cells below.\n",
    "\n",
    "The next cell downloads it from Google Cloud Storage and saves it in the Colaboratory VM at `/models/<model_name>`.\n",
    "\n",
    "This model isn't permanently saved in the Colaboratory VM; you'll have to redownload it if you want to retrain it at a later time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "P8wSlgXoDPCR",
    "outputId": "36d94eaa-129b-4039-93ec-a32d8f7c1983"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching checkpoint: 1.05Mit [00:00, 424Mit/s]                                                      \n",
      "Fetching encoder.json: 1.05Mit [00:00, 7.27Mit/s]\n",
      "Fetching hparams.json: 1.05Mit [00:00, 390Mit/s]                                                    \n",
      "Fetching model.ckpt.data-00000-of-00001: 1.42Git [00:32, 44.2Mit/s]                                 \n",
      "Fetching model.ckpt.index: 1.05Mit [00:00, 211Mit/s]                                                \n",
      "Fetching model.ckpt.meta: 1.05Mit [00:00, 8.24Mit/s]\n",
      "Fetching vocab.bpe: 1.05Mit [00:00, 8.84Mit/s]\n"
     ]
    }
   ],
   "source": [
    "gpt2.download_gpt2(model_name=\"345M\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N8KXuKWzQSsN"
   },
   "source": [
    "## Mounting Google Drive\n",
    "\n",
    "The best way to get input text to-be-trained into the Colaboratory VM, and to get the trained model *out* of Colaboratory, is to route it through Google Drive *first*.\n",
    "\n",
    "Running this cell (which will only work in Colaboratory) will mount your personal Google Drive in the VM, which later cells can use to get data in/out. (it will ask for an auth code; that auth is not saved anywhere)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "puq4iC6vUAHc",
    "outputId": "9efb1b34-dd98-45ac-a716-fa4bf8132d26"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "gpt2.mount_gdrive()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load text file into GPT2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-Z6okFD8VKtS"
   },
   "outputs": [],
   "source": [
    "gpt2.copy_file_from_gdrive(file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LdpZQXknFNY3"
   },
   "source": [
    "## Finetune GPT-2\n",
    "\n",
    "The next cell will start the actual finetuning of GPT-2. It creates a persistent TensorFlow session which stores the training config, then runs the training for the specified number of `steps`. (to have the finetuning run indefinitely, set `steps = -1`)\n",
    "\n",
    "The model checkpoints will be saved in `/checkpoint/run1` by default. The checkpoints are saved every 500 steps (can be changed) and when the cell is stopped.\n",
    "\n",
    "The training might time out after 4ish hours; make sure you end training and save the results so you don't lose them!\n",
    "\n",
    "**IMPORTANT NOTE:** If you want to rerun this cell, **restart the VM first** (Runtime -> Restart Runtime). You will need to rerun imports but not recopy files.\n",
    "\n",
    "Other optional-but-helpful parameters for `gpt2.finetune`:\n",
    "\n",
    "\n",
    "*  **`restore_from`**: Set to `fresh` to start training from the base GPT-2, or set to `latest` to restart training from an existing checkpoint.\n",
    "* **`sample_every`**: Number of steps to print example output\n",
    "* **`print_every`**: Number of steps to print training progress.\n",
    "* **`learning_rate`**:  Learning rate for the training. (default `1e-4`, can lower to `1e-5` if you have <1MB input data)\n",
    "*  **`run_name`**: subfolder within `checkpoint` to save the model. This is useful if you want to work with multiple models (will also need to specify  `run_name` when loading the model)\n",
    "* **`overwrite`**: Set to `True` if you want to continue finetuning an existing model (w/ `restore_from='latest'`) without creating duplicate copies. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aeXshJM-Cuaf",
    "outputId": "a3c75caa-917b-4818-ca2d-d78610d8b6f2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading checkpoint models/124M/model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from models/124M/model.ckpt\n",
      "Loading dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.80s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset has 338025 tokens\n",
      "Training...\n",
      "[10 | 17.67] loss=3.69 avg=3.69\n",
      "[20 | 30.36] loss=3.60 avg=3.65\n",
      "[30 | 43.05] loss=3.37 avg=3.55\n",
      "[40 | 55.74] loss=3.32 avg=3.49\n",
      "[50 | 68.44] loss=3.29 avg=3.45\n",
      "[60 | 81.11] loss=3.32 avg=3.43\n",
      "[70 | 93.78] loss=3.33 avg=3.41\n",
      "[80 | 106.45] loss=3.09 avg=3.37\n",
      "[90 | 119.15] loss=2.98 avg=3.33\n",
      "[100 | 131.85] loss=3.27 avg=3.32\n",
      "[110 | 144.56] loss=2.91 avg=3.28\n",
      "[120 | 157.26] loss=3.02 avg=3.26\n",
      "[130 | 169.95] loss=3.39 avg=3.27\n",
      "[140 | 182.64] loss=2.78 avg=3.23\n",
      "[150 | 195.35] loss=3.09 avg=3.22\n",
      "[160 | 208.06] loss=2.96 avg=3.20\n",
      "[170 | 220.74] loss=2.94 avg=3.19\n",
      "[180 | 233.43] loss=2.96 avg=3.17\n",
      "[190 | 246.13] loss=2.96 avg=3.16\n",
      "[200 | 258.83] loss=2.91 avg=3.15\n",
      "======== SAMPLE 1 ========\n",
      ", the king and princess at the king's side. Come, sirrah, take the king's hand; the queen's husband is out to fetch him.\n",
      "'Tis all right; but, to win thy son back,\n",
      "Till he be thy heir, thou wilt swear by thine hand,\n",
      "And that thy husband is a king. Come, gentlemen, have a word with me,\n",
      "And let's get thee to bed, for I am no king.\n",
      "\n",
      "DUKE VINCENTIO:\n",
      "Well, it shall prove no more than an ague; for,\n",
      "Your majesty, if this be so, you will not stay,\n",
      "Or--\n",
      "\n",
      "WARWICK:\n",
      "Go, go; be gone, and go to bed with me.\n",
      "\n",
      "DUKE VINCENTIO:\n",
      "No, no, go; I am too ill to stay: yet, by my fortune,\n",
      "My health, or God's, have been so much the better\n",
      "That if the plague should be at your hands,\n",
      "All the king's enemies were and shall be here to me,\n",
      "And I shall be much better, by my fortune;\n",
      "If it be, I cannot stay here to-night.\n",
      "\n",
      "SOMERSET:\n",
      "Be merry, Warwick,\n",
      "All men are coming to bed. Please you to stay.\n",
      "\n",
      "BUCKINGHAM:\n",
      "Away now; we'll meet with a fight.\n",
      "\n",
      "RICHMOND:\n",
      "We are gone with him; we'll go with him.\n",
      "\n",
      "BRUTUS:\n",
      "Well, now, good gentlemen; there are a great thousands:\n",
      "They march by, and with them: we must have their\n",
      "hounds after us. If they so please, go with them.\n",
      "\n",
      "DUKE VINCENTIO:\n",
      "What for? let's go with them, and we shall be\n",
      "a king for this and that and many thousands of us,\n",
      "For we are but the number of the army.\n",
      "\n",
      "SOMERSET:\n",
      "You must not stay? I will stay with you both.\n",
      "\n",
      "BRUTUS:\n",
      "Well, now, good friends, what for?\n",
      "\n",
      "BRUTUS:\n",
      "The people will be angry at my being gone,\n",
      "And say that thou hast never been away, I will not go.\n",
      "\n",
      "SOMERSET:\n",
      "\n",
      "BRUTUS:\n",
      "I pray thee, if I was not gone, I would, sir,\n",
      "Be to my father again to deliver this good\n",
      "With which I was lost before and lost\n",
      "But now, like a traitor to your king's honour,\n",
      "Be gone, and die on that ground\n",
      "Of treason and all the people's enemies.\n",
      "\n",
      "SOMERSET:\n",
      "\n",
      "DUKE VINCENTIO:\n",
      "I will to the churchyard\n",
      "And find your brother.\n",
      "\n",
      "WARWICK:\n",
      "Here's a man for you: I'll to the churchyard; go.\n",
      "\n",
      "SOMERSET:\n",
      "Good, then you both must be men.\n",
      "\n",
      "First Servant:\n",
      "\n",
      "DUKE VINCENTIO:\n",
      "What, Warwick?\n",
      "\n",
      "WARWICK:\n",
      "Why, what, I was struck down?\n",
      "\n",
      "DUKE VINCENTIO:\n",
      "You'll remember, sir, I was not hit by a\n",
      "bow; I was struck down by a horse.\n",
      "\n",
      "Second Servant,\n",
      "\n",
      "DUKE VINCENTIO:\n",
      "What, Warwick?\n",
      "\n",
      "WARWICK:\n",
      "Why, good Warwick! I am struck down, sir,\n",
      "Your brother did strike me down.\n",
      "\n",
      "WARWICK:\n",
      "Ay, sir, at my brother's hand. I had slain him,\n",
      "With one blow, and, with a second,\n",
      "To the heart of the enemy. He is gone, sir:\n",
      "This is true, good lord. I did kill him before,\n",
      "Or else he would not have fought\n",
      "The Roman king that he was: in my life\n",
      "I've lost twenty thousand lives so in France alone.\n",
      "\n",
      "DUKE VINCENTIO:\n",
      "What, Warwick?\n",
      "\n",
      "WARWICK:\n",
      "You must, then, go with me hence, for I will give thee\n",
      "Our goodly peace: there's a plague\n",
      "And you must do more\n",
      "To quench it. Go, go; the king shall be king.\n",
      "\n",
      "POMPERSY:\n",
      "\n",
      "Second Servant:\n",
      "You know my voice, as it seeth upon you\n",
      "And I know not'st mine, that I should here pronounce\n",
      "The will of the great prince, or that his hand\n",
      "Should strike you! There is a traitor here:\n",
      "Go, and to the city\n",
      "And not one but in the churchyard hear me.\n",
      "\n",
      "First Servant:\n",
      "I am struck down.\n",
      "\n",
      "WARWICK:\n",
      "I am struck, sir, down;\n",
      "\n",
      "[210 | 281.19] loss=2.83 avg=3.13\n",
      "[220 | 293.87] loss=3.02 avg=3.12\n",
      "[230 | 306.55] loss=2.57 avg=3.10\n",
      "[240 | 319.23] loss=2.98 avg=3.09\n",
      "[250 | 331.92] loss=2.70 avg=3.07\n",
      "[260 | 344.61] loss=2.69 avg=3.06\n",
      "[270 | 357.29] loss=2.68 avg=3.04\n",
      "[280 | 369.96] loss=2.60 avg=3.02\n",
      "[290 | 382.64] loss=2.63 avg=3.01\n",
      "[300 | 395.32] loss=2.82 avg=3.00\n",
      "[310 | 408.02] loss=2.38 avg=2.98\n",
      "[320 | 420.71] loss=2.55 avg=2.96\n",
      "[330 | 433.38] loss=2.63 avg=2.95\n",
      "[340 | 446.07] loss=2.22 avg=2.93\n",
      "[350 | 458.75] loss=2.51 avg=2.91\n",
      "[360 | 471.44] loss=2.59 avg=2.90\n",
      "[370 | 484.13] loss=2.49 avg=2.89\n",
      "[380 | 496.82] loss=2.43 avg=2.87\n",
      "[390 | 509.49] loss=2.46 avg=2.86\n",
      "[400 | 522.16] loss=2.33 avg=2.84\n",
      "======== SAMPLE 1 ========\n",
      " down his face, and thrusts it upon mine? he had not the heart to do this, but that I would be his friend.\n",
      "\n",
      "GLOUCESTER:\n",
      "And to have this revenge.\n",
      "\n",
      "HASTINGS:\n",
      "Why, now he is gone to slaughter me.\n",
      "\n",
      "ANTIGONUS:\n",
      "He was once his friend.\n",
      "\n",
      "ISABELLA:\n",
      "Ay, he was; but I am too dear to be his friend.\n",
      "If aught else in his nature should keep his friend, I would damn him:\n",
      "But he was too dear for a friend to be friend:\n",
      "If he were friend, God, and his friends, he should be so,\n",
      "That he should not, for I have in him too much gavings:\n",
      "But he and I are friends, though we have tongues by\n",
      "both, but we do not see one to be cruel.\n",
      "\n",
      "GLOUCESTER:\n",
      "How now! is this his revenge?\n",
      "\n",
      "HASTINGS:\n",
      "It is his revenge.\n",
      "\n",
      "ISABELLA:\n",
      "Why, so?\n",
      "\n",
      "GLOUCESTER:\n",
      "As a spite; a spite of yourself\n",
      "To have more than would make him better.\n",
      "\n",
      "ISABELLA:\n",
      "What's the matter with you?\n",
      "\n",
      "HASTINGS:\n",
      "Why, you are such a thing\n",
      "That he should do you wrong.\n",
      "\n",
      "GLOUCESTER:\n",
      "I may be said to be better, if you kill him.\n",
      "\n",
      "HASTINGS:\n",
      "I may be as good as your word, if you kill him.\n",
      "\n",
      "ISABELLA:\n",
      "He's your friend.\n",
      "\n",
      "GLOUCESTER:\n",
      "He's a good man.\n",
      "\n",
      "HASTINGS:\n",
      "A good man\n",
      "That would use my gash in the ground.\n",
      "\n",
      "ISABELLA:\n",
      "No more.\n",
      "\n",
      "HASTINGS:\n",
      "But he's your foe: he would use mine gash in the ground.\n",
      "\n",
      "ISABELLA:\n",
      "Why, then he's his friend.\n",
      "\n",
      "HASTINGS:\n",
      "No more.\n",
      "\n",
      "GLOUCESTER:\n",
      "What, am I his friend yet?\n",
      "\n",
      "HASTINGS:\n",
      "I am his friend, if he would use your gash in the ground.\n",
      "\n",
      "ISABELLA:\n",
      "Where is he.\n",
      "\n",
      "HASTINGS:\n",
      "Where he is.\n",
      "\n",
      "ISABELLA:\n",
      "He is in your tent.\n",
      "\n",
      "HASTINGS:\n",
      "Where he lies.\n",
      "\n",
      "ISABELLA:\n",
      "He's in mine tent.\n",
      "\n",
      "HASTINGS:\n",
      "Who? are you there.\n",
      "\n",
      "ISABELLA:\n",
      "Where the butcher's shop should be.\n",
      "\n",
      "HASTINGS:\n",
      "Who? are you there?\n",
      "\n",
      "ISABELLA:\n",
      "I will not hence to-day: I am come to save you,\n",
      "as long as he is dead.\n",
      "\n",
      "HASTINGS:\n",
      "What will you\n",
      "do hereafter when he comes?\n",
      "Where is your pack?\n",
      "\n",
      "ISABELLA:\n",
      "Here.\n",
      "\n",
      "HASTINGS:\n",
      "Where is your pack?\n",
      "\n",
      "ISABELLA:\n",
      "You may call your sheep.\n",
      "\n",
      "HASTINGS:\n",
      "You may call your sheep.\n",
      "\n",
      "ISABELLA:\n",
      "You may call your sheep; it is worse than death.\n",
      "\n",
      "HASTINGS:\n",
      "You may call your sheep.\n",
      "\n",
      "ISABELLA:\n",
      "You say you will obey.\n",
      "\n",
      "HASTINGS:\n",
      "You will obey.\n",
      "\n",
      "ISABELLA:\n",
      "You are all traitors.\n",
      "\n",
      "HASTINGS:\n",
      "All traitors.\n",
      "\n",
      "ISABELLA:\n",
      "You're traitors too,\n",
      "That in this you are of opposite kind to us.\n",
      "\n",
      "HASTINGS:\n",
      "Do you not understand?\n",
      "\n",
      "ISABELLA:\n",
      "\n",
      "HASTINGS:\n",
      "No.\n",
      "\n",
      "ISABELLA:\n",
      "\n",
      "HASTINGS:\n",
      "Do you not understand?\n",
      "\n",
      "ISABELLA:\n",
      "No.\n",
      "\n",
      "HASTINGS:\n",
      "No.\n",
      "\n",
      "ISABELLA:\n",
      "\n",
      "HASTINGS:\n",
      "Do you not understand?\n",
      "\n",
      "ISABELLA:\n",
      "No, sir.\n",
      "\n",
      "HASTINGS:\n",
      "No.\n",
      "\n",
      "ISABELLA:\n",
      "\n",
      "HASTINGS:\n",
      "Do you not understand?\n",
      "\n",
      "ISABELLA:\n",
      "\n",
      "HASTINGS:\n",
      "Do you not understand?\n",
      "\n",
      "ISABELLA:\n",
      "\n",
      "HASTINGS:\n",
      "Do you not understand?\n",
      "\n",
      "ISABELLA:\n",
      "No, sir.\n",
      "\n",
      "HASTINGS:\n",
      "Do you not understand?\n",
      "\n",
      "ISABELLA:\n",
      "\n",
      "HASTINGS:\n",
      "No, sir.\n",
      "\n",
      "ISABELLA:\n",
      "\n",
      "HASTINGS:\n",
      "No, sir.\n",
      "\n",
      "[410 | 543.43] loss=1.97 avg=2.82\n",
      "[420 | 556.12] loss=2.11 avg=2.80\n",
      "[430 | 568.81] loss=2.33 avg=2.78\n",
      "[440 | 581.50] loss=2.00 avg=2.76\n",
      "[450 | 594.18] loss=2.19 avg=2.75\n",
      "[460 | 606.85] loss=2.36 avg=2.74\n",
      "[470 | 619.54] loss=1.75 avg=2.71\n",
      "[480 | 632.22] loss=1.81 avg=2.69\n",
      "[490 | 644.92] loss=1.85 avg=2.67\n",
      "[500 | 657.61] loss=1.70 avg=2.64\n",
      "Saving checkpoint/run1/model-500\n",
      "[510 | 672.84] loss=1.75 avg=2.62\n",
      "[520 | 685.51] loss=1.57 avg=2.59\n",
      "[530 | 698.18] loss=1.63 avg=2.57\n",
      "[540 | 710.86] loss=2.03 avg=2.56\n",
      "[550 | 723.55] loss=1.78 avg=2.54\n",
      "[560 | 736.23] loss=1.91 avg=2.52\n",
      "[570 | 748.90] loss=1.57 avg=2.50\n",
      "[580 | 761.58] loss=1.28 avg=2.47\n",
      "[590 | 774.26] loss=1.41 avg=2.45\n",
      "[600 | 786.94] loss=1.57 avg=2.43\n",
      "======== SAMPLE 1 ========\n",
      " my wife and by sojourn here with the king of France,\n",
      "I fear my life or mine.\n",
      "\n",
      "BRUTUS:\n",
      "Why wilt thou go to such a deal of hurt,\n",
      "To seek for redress of our wrongs?\n",
      "\n",
      "SICINIUS:\n",
      "I do beseech you, go not to such a place,\n",
      "Because any man in Vienna or here\n",
      "Can mend our unhappy state: our troubles\n",
      "Can be sorted by a king; no man can take away\n",
      "Our counsel: every fault is his own; therefore\n",
      "We advise you to temperate us; at least\n",
      "To think on what to say.\n",
      "\n",
      "BRUTUS:\n",
      "This gentleman will\n",
      "Give you best advantage.\n",
      "\n",
      "SICINIUS:\n",
      "He must, if he be wise.\n",
      "\n",
      "BRUTUS:\n",
      "I tell thee, gentlemen,\n",
      "we are not so far apart: think upon\n",
      "'Sicinius Consisting himself\n",
      "Nor man, woman, or child, within this state\n",
      "Of perfect peace.'\n",
      "\n",
      "SICINIUS:\n",
      "You swear the honourable lie\n",
      "To you and others abroad!\n",
      "\n",
      "BRUTUS:\n",
      "I am in no way opposed; but I would\n",
      "beguile our countrymen by that title.\n",
      "\n",
      "SICINIUS:\n",
      "Then, by degrees and degrees, what are you?\n",
      "\n",
      "BRUTUS:\n",
      "My name is Rutland; and I am a Roman,\n",
      "Having authority, to seek a friendly\n",
      "Peer unto my brother;\n",
      "As I can from your town and from your\n",
      "prison promise; which is all, that is all,\n",
      "I can do in pleading for your brother's speedy death.\n",
      "\n",
      "SICINIUS:\n",
      "Good faith, you must die to-night.\n",
      "\n",
      "BRUTUS:\n",
      "To-morrow.\n",
      "\n",
      "SICINIUS:\n",
      "I will, ere I am out of your town.\n",
      "\n",
      "BRUTISHER:\n",
      "Go to:\n",
      "Go ask for him the next day.\n",
      "\n",
      "SICORIA:\n",
      "To-morrow.\n",
      "\n",
      "GREMIO:\n",
      "Yes, sir,--\n",
      "\n",
      "PETRUCHIO:\n",
      "To-morrow morning.\n",
      "\n",
      "GREMIO:\n",
      "Then, you shall be satisfied.\n",
      "\n",
      "PETRUCHIO:\n",
      "I fear, sir, you shall find not.\n",
      "\n",
      "GREMIO:\n",
      "In such a case, it may be thought, you shall find me but a\n",
      "commission-man. I have for my services purchased\n",
      "these clothes; they are not call'd service, for\n",
      "they are made for companies. Come, all, and welcome you with open arms:\n",
      "if any one of you be of any complaint,\n",
      "report at our post.\n",
      "\n",
      "PETRUCHIO:\n",
      "I am satisfied.\n",
      "\n",
      "HORTENSIO:\n",
      "I am satisfied.\n",
      "\n",
      "PETRUCHIO:\n",
      "If your maid follows, all my revenue's all; and this\n",
      "will bring you this gentleman: stay awhile,\n",
      "and you shall have assurance of pretty things:\n",
      "therefore, you shall have no cap, wit, or form.\n",
      "\n",
      "HORTENSIO:\n",
      "I am satisfied.\n",
      "\n",
      "PETRUCHIO:\n",
      "I am satisfied.\n",
      "\n",
      "LUCENTIO:\n",
      "'Faith, mercy;' Petruchio! 'tis morning.\n",
      "\n",
      "HORTENSIO:\n",
      "Forever.\n",
      "\n",
      "PETRUCHIO:\n",
      "Nay, I am satisfied.\n",
      "\n",
      "HORTENSIO:\n",
      "'Faith, mercy;' Petruchio! 'tis morning.\n",
      "\n",
      "PETRUCHIO:\n",
      "Daughter, your father comes by night.\n",
      "\n",
      "BAPTISTA:\n",
      "Nay, good.\n",
      "\n",
      "PETRUCHIO:\n",
      "Nay, I have believed thee far, far too long;\n",
      "and I have long since given way to my loathsome wit.\n",
      "\n",
      "LUCENTIO:\n",
      "'Bag of twenty-five tricks,' do you mean, daughter?\n",
      "\n",
      "PETRUCHIO:\n",
      "Nay, what? no, no, good faith; what, purse of twenty?\n",
      "\n",
      "LUCENTIO:\n",
      "'Three Volts of Five Pounds,' do you mean?\n",
      "\n",
      "PETRUCHIO:\n",
      "Fie, fie!\n",
      "\n",
      "HORTENSIO:\n",
      "'Nay, fie, fie!'\n",
      "\n",
      "PETRUCHIO:\n",
      "Nay, fie!\n",
      "\n",
      "LUCENTIO:\n",
      "'Nay, fie!'\n",
      "\n",
      "HORTENSIO:\n",
      "'Nay!'\n",
      "\n",
      "PETRUCHIO:\n",
      "Naw! nay! nay!\n",
      "\n",
      "PETRUCHIO:\n",
      "Naw! nay! nay!\n",
      "\n",
      "GREMIO:\n",
      "Hortensio, hark!\n",
      "\n",
      "\n",
      "[610 | 808.21] loss=1.22 avg=2.40\n",
      "[620 | 820.89] loss=1.43 avg=2.38\n",
      "[630 | 833.56] loss=1.40 avg=2.36\n",
      "[640 | 846.25] loss=1.11 avg=2.34\n",
      "[650 | 858.92] loss=1.96 avg=2.33\n",
      "[660 | 871.59] loss=1.41 avg=2.31\n",
      "[670 | 884.29] loss=1.48 avg=2.29\n",
      "[680 | 896.97] loss=1.02 avg=2.27\n",
      "[690 | 909.67] loss=1.03 avg=2.24\n",
      "[700 | 922.35] loss=1.02 avg=2.22\n",
      "[710 | 935.02] loss=1.01 avg=2.19\n",
      "[720 | 947.70] loss=0.91 avg=2.17\n",
      "[730 | 960.38] loss=0.91 avg=2.14\n",
      "[740 | 973.06] loss=0.81 avg=2.12\n",
      "[750 | 985.75] loss=0.96 avg=2.10\n",
      "[760 | 998.44] loss=0.80 avg=2.07\n",
      "[770 | 1011.11] loss=0.62 avg=2.05\n",
      "[780 | 1023.78] loss=0.84 avg=2.02\n",
      "[790 | 1036.45] loss=0.60 avg=2.00\n",
      "[800 | 1049.13] loss=0.78 avg=1.98\n",
      "======== SAMPLE 1 ========\n",
      "Heart:\n",
      "If but they\n",
      "No more would affright me with him:\n",
      "O, we would not do thus, keeping as we are;\n",
      "For, were it known, we should make haste,\n",
      "And pouring over many glasses we took.\n",
      "No sooner did I resign my place,\n",
      "Than I now should depart it, than\n",
      "Our visage was changed to one of change:\n",
      "O, we were misled by a falsehood!\n",
      "The king our father, that with the more truth\n",
      "Shall ne'er appear again, speaks me on.\n",
      "\n",
      "QUEEN:\n",
      "For myself? O, speak with a trembling heart,\n",
      "Ere I can say 'I.'\n",
      "\n",
      "DUKE VINCENTIO:\n",
      "How often have I sounded the sad note of death.\n",
      "\n",
      "BENVOLIO:\n",
      "Ay, in the voice of some drowned man.\n",
      "\n",
      "LUCIO:\n",
      "How often have I said 'It is a world of woe.'\n",
      "Would I could speak a Italian to this native,\n",
      "Making him ask me why he parted with him,\n",
      "Such a business as this did ask me.\n",
      "\n",
      "BENVOLIO:\n",
      "O Thou art drowned, and I myself are.\n",
      "Drown, thou, and what thou art. What, art thou, in these\n",
      "years? what hast thou, that is, caught in the waves?\n",
      "How many times have I said 'it is a world of woe.'?\n",
      "\n",
      "LUCIO:\n",
      "Ay, an hundred times; for many of those were not\n",
      "my shallow deep deep advice. But that I know,\n",
      "It is enough; and I never was proved.\n",
      "\n",
      "BENVOLIO:\n",
      "Why, then thou wilt speak with me of other men.\n",
      "\n",
      "LUCIO:\n",
      "The one did call me a fool; while the other hath\n",
      "deliver'd me perfectly true, although I have\n",
      "sometimes said 'it is a world of woe.'\n",
      "\n",
      "BENVOLIO:\n",
      "You are simply right; for many years I had\n",
      "lay hold of a friar who ever since had\n",
      "helmed me in any good business; was always\n",
      "at my feet; and he accused me of infidelity\n",
      "sometimes till now; would not answer me, other\n",
      "loved me; and at other times he would come up\n",
      "home with me in hideous terror; would not let\n",
      "him visit me in his torments, but would beseech\n",
      "me to acquaint him of my fearful state;\n",
      "Whenever he should come to me, he would leave his\n",
      "prison with a message telling him where\n",
      "he should send the prisoner: where he did\n",
      "enter, so to speak, he would weep out my name,\n",
      "deliver my confessor cold breaths, and with eager\n",
      "bravery enter yet another prisoner\n",
      "in a most frightful manner.\n",
      "\n",
      "First Conspirator:\n",
      "At this point did I set down the sacrament;\n",
      "For who could have beheld a naked soul in\n",
      "semi-detached bondage?\n",
      "\n",
      "BENVOLIO:\n",
      "Who would, then, so cover his eyes with such a\n",
      "suit?\n",
      "\n",
      "First Conspirator:\n",
      "Nay, wherefore gaze o'er his eyelids?\n",
      "\n",
      "BENVOLIO:\n",
      "Come, come, look o'er his eyes; nay, come, come back\n",
      "on his malicious tongue, and, with so loud a\n",
      "bawd, set on his malicious thrust.\n",
      "\n",
      "First Conspirator:\n",
      "My master is come.\n",
      "\n",
      "LUCIO:\n",
      "Fie, fie, fois! where's the master?\n",
      "\n",
      "First Conspirator:\n",
      "My master is coming home.\n",
      "\n",
      "LUCIO:\n",
      "The duke, leaving the priore general, and\n",
      "having power i' the consulship, are gone\n",
      "to visit the slutterers and the fitter patricians;\n",
      "for the great dictator is come. For these\n",
      "secrets I'll tell them, the common plaints of their\n",
      "heart, which they profess to abideth in\n",
      "bearing him.\n",
      "\n",
      "Second Conspirator:\n",
      "Here's well met.\n",
      "\n",
      "LUCIO:\n",
      "Where is the senate?\n",
      "\n",
      "Second Conspirator:\n",
      "The people's chamber is on the city side.\n",
      "\n",
      "LUCIO:\n",
      "Come, come, we hear great work's'n be done.\n",
      "The duke will come soon, the people's chamber set.\n",
      "\n",
      "First Conspirator:\n",
      "I think he will.\n",
      "\n",
      "LUCIO:\n",
      "And will come very shortly.\n",
      "\n",
      "Second Conspirator:\n",
      "He will deliver us all.\n",
      "\n",
      "First Conspirator:\n",
      "Here do I leave you. Here do I leave you.\n",
      "\n",
      "LUCIO:\n",
      "Good time of day!\n",
      "\n",
      "Second Conspirator:\n",
      "That lies expressly in my purse.\n",
      "\n",
      "LUCIO:\n",
      "\n",
      "\n",
      "[810 | 1070.48] loss=0.99 avg=1.96\n",
      "[820 | 1083.16] loss=0.76 avg=1.94\n",
      "[830 | 1095.83] loss=0.82 avg=1.92\n",
      "[840 | 1108.51] loss=0.43 avg=1.89\n",
      "[850 | 1121.19] loss=0.86 avg=1.87\n",
      "[860 | 1133.87] loss=0.51 avg=1.85\n",
      "[870 | 1146.55] loss=0.45 avg=1.83\n",
      "[880 | 1159.26] loss=0.45 avg=1.80\n",
      "[890 | 1171.93] loss=0.44 avg=1.78\n",
      "[900 | 1184.60] loss=0.52 avg=1.76\n",
      "[910 | 1197.27] loss=0.52 avg=1.74\n",
      "[920 | 1209.94] loss=0.47 avg=1.72\n",
      "[930 | 1222.63] loss=0.76 avg=1.70\n",
      "[940 | 1235.30] loss=0.59 avg=1.68\n",
      "[950 | 1247.98] loss=0.54 avg=1.66\n",
      "[960 | 1260.67] loss=0.30 avg=1.64\n",
      "[970 | 1273.36] loss=0.40 avg=1.62\n",
      "[980 | 1286.03] loss=0.46 avg=1.60\n",
      "[990 | 1298.70] loss=0.37 avg=1.58\n",
      "[1000 | 1311.38] loss=0.52 avg=1.57\n",
      "Saving checkpoint/run1/model-1000\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/training/saver.py:971: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to delete files with this prefix.\n"
     ]
    }
   ],
   "source": [
    "sess = gpt2.start_tf_sess()\n",
    "\n",
    "gpt2.finetune(sess,\n",
    "              dataset=file_name,\n",
    "              model_name='124M',\n",
    "              steps=1000,\n",
    "              restore_from='fresh',\n",
    "              run_name='run1',\n",
    "              print_every=10,\n",
    "              sample_every=200,\n",
    "              save_every=500\n",
    "              )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IXSuTNERaw6K"
   },
   "source": [
    "After the model is trained, you can copy the checkpoint folder to your own Google Drive.\n",
    "\n",
    "If you want to download it to your personal computer, it's strongly recommended you copy it there first, then download from Google Drive. The checkpoint folder is copied as a `.rar` compressed file; you can download it and uncompress it locally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VHdTL8NDbAh3"
   },
   "outputs": [],
   "source": [
    "gpt2.copy_checkpoint_to_gdrive(run_name='run1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qQJgV_b4bmzd"
   },
   "source": [
    "You're done! Feel free to go to the **Generate Text From The Trained Model** section to generate text based on your retrained model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pel-uBULXO2L"
   },
   "source": [
    "## Load a Trained Model Checkpoint\n",
    "\n",
    "Running the next cell will copy the `.rar` checkpoint file from your Google Drive into the Colaboratory VM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DCcx5u7sbPTD"
   },
   "outputs": [],
   "source": [
    "gpt2.copy_checkpoint_from_gdrive(run_name='run1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RTa6zf3e_9gV"
   },
   "source": [
    "The next cell will allow you to load the retrained model checkpoint + metadata necessary to generate text.\n",
    "\n",
    "**IMPORTANT NOTE:** If you want to rerun this cell, **restart the VM first** (Runtime -> Restart Runtime). You will need to rerun imports but not recopy files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-fxL77nvAMAX",
    "outputId": "8938432a-3b86-4102-f32b-362721ecb897"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading checkpoint checkpoint/run1/model-1000\n",
      "INFO:tensorflow:Restoring parameters from checkpoint/run1/model-1000\n"
     ]
    }
   ],
   "source": [
    "sess = gpt2.start_tf_sess()\n",
    "gpt2.load_gpt2(sess, run_name='run1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ClJwpF_ACONp"
   },
   "source": [
    "## Generate Text From The Trained Model\n",
    "\n",
    "After you've trained the model or loaded a retrained model from checkpoint, you can now generate text. `generate` generates a single text from the loaded model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eZIaw66yovbf"
   },
   "outputs": [],
   "source": [
    "ctx = input(\"Context: \")\n",
    "qst = input(\"Question: \")\n",
    "ans = \"[ANSWER]:\"\n",
    "pre = '<|startoftext|>\\n[CONTEXT]: ' + ctx + \"\\n[QUESTION]:\" + qst + \"\\n\" + ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zYbYbVt8oypn"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4RNY6RBI9LmL",
    "outputId": "82574eaa-d39a-4665-b611-e5172848da57"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norfolk:\n",
      "Why, Norfolk, I am Norfolk;\n",
      "And yet I am not traitor, coward, coward,\n",
      "In the view of the crown.\n",
      "\n",
      "DORSET:\n",
      "O Dorset, throw up your hands.\n",
      "\n",
      "NORFOLK:\n",
      "Then, Norfolk, do not say you fear the king.\n",
      "\n",
      "DORSET:\n",
      "Norfolk, throw up your hands.\n",
      "\n",
      "NORFOLK:\n",
      "Norfolk, do not say you fear the king.\n",
      "\n",
      "DORSET:\n",
      "O God! my heart is heavy, and I havnt time to speak;\n",
      "But as the time elapses, so mine is not so;\n",
      "For never had I a more just disposition\n",
      "To trouble the time o'er-hand of wrath.\n",
      "\n",
      "NORFOLK:\n",
      "Here comes a madman to thine.\n",
      "\n",
      "DORSET:\n",
      "Nurse! my lady! O woful, bloody, blood-sucking,\n",
      "extranelly guilty hour!\n",
      "\n",
      "DORSET:\n",
      "How white is that note?\n",
      "\n",
      "NORFOLK:\n",
      "That Ned bloody slew, O, what a fool was\n",
      "That worke so! Where is he now? is he dead?\n",
      "\n",
      "DORSET:\n",
      "He's in the morrow, or near the morrow;\n",
      "Whose neck is the block o' the hams bear,\n",
      "That hung about the neck and is hanging\n",
      "About the father's head, hanging therefrom.\n",
      "\n",
      "DORSET:\n",
      "Is he dead?\n",
      "\n",
      "NORFOLK:\n",
      "Ay, or near the moon, or near the eclipsing\n",
      "She-angel, who with a gracious soul\n",
      "Strive with the white dove towards the light,\n",
      "Unto the burning chariot,\n",
      "And with that say, 'I love thy daughter'?\n",
      "\n",
      "DORSET:\n",
      "I do: and go I do:\n",
      "And come I unto the vault,\n",
      "Where, after the fashion of time, I give my rest\n",
      "My oft-parodied arm\n",
      "To pant, this ancient and graceful lady,\n",
      "Who ne'er was born gentle.\n",
      "\n",
      "DORSET:\n",
      "She is, sir, within.\n",
      "\n",
      "LORD FITZWATER:\n",
      "How white is this boy, that wither so?\n",
      "\n",
      "NORTHUMBERLAND:\n",
      "White as a crow that is within his eyepatch.\n",
      "\n",
      "LORD FITZWATER:\n",
      "So Dorset calls him nay, if he makest to remain\n",
      "And then call me sallow and wet.\n",
      "\n",
      "NORTHUMBERLAND:\n",
      "Why, then he should find me dry and wither'd:\n",
      "Wash'd with tears I would lose myself,\n",
      "And waken not my children nor my wife.\n",
      "\n",
      "LORD FITZWATER:\n",
      "Nay, then he'll come by me chastely.\n",
      "\n",
      "DORSET:\n",
      "Ay, and without more ceremony:\n",
      "I would by treachery do miscall.\n",
      "\n",
      "NORTHUMBERLAND:\n",
      "Why, so: yet, by Dorset I know\n",
      "He has a more profound hatred\n",
      "Than we, or we billeted by our birth,\n",
      "Or by property or by any other use;\n",
      "And yet here he would not seem to be drawn\n",
      "Any other way. Come, knock, and ask me what I have been\n",
      "That is not a bastard of this house.\n",
      "\n",
      "DORSET:\n",
      "How, hither, how, and what?\n",
      "\n",
      "LORD FITZWATER:\n",
      "I do not know; nor, nor, nor; for, by Dorset,\n",
      "He has a more profound malice in him,\n",
      "A charmer in him, than we, or any of us,\n",
      "Who, by our birth, does not seem to be drawn,\n",
      "Bores not this place.\n",
      "\n",
      "DORSET:\n",
      "O, by Dorset, my master!\n",
      "\n",
      "LORD FITZWATER:\n",
      "By this, I beseech you, on your life.\n",
      "\n",
      "NORTHUMBERLAND:\n",
      "Why, then, on my master's life?\n",
      "\n",
      "DORSET:\n",
      "O, sir, on his, on his life!\n",
      "\n",
      "LORD FITZWATER:\n",
      "Why then, on his, on his life?\n",
      "\n",
      "DORSET:\n",
      "O, good sir, you may be of comfort.\n",
      "\n",
      "LORD FITZWATER:\n",
      "Good lord, I am in so much comfort\n",
      "That I am afraid to sleep.\n",
      "\n",
      "DORSET:\n",
      "Nay, then, give me counsel.\n",
      "\n",
      "LORD FITZWATER:\n",
      "I am afraid of colds, too: I think I see colds\n",
      "everywhere; and I am stung.\n",
      "\n",
      "DORSET:\n",
      "Thou wilt ne'er be cold.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gpt2.generate(sess, run_name='run1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oF4-PqF0Fl7R"
   },
   "source": [
    "If you're creating an API based on your model and need to pass the generated text elsewhere, you can do `text = gpt2.generate(sess, return_as_list=True)[0]`\n",
    "\n",
    "You can also pass in a `prefix` to the generate function to force the text to start with a given character sequence and generate text from there (good if you add an indicator when the text starts).\n",
    "\n",
    "You can also generate multiple texts at a time by specifing `nsamples`. Unique to GPT-2, you can pass a `batch_size` to generate multiple samples in parallel, giving a massive speedup (in Colaboratory, set a maximum of 20 for `batch_size`).\n",
    "\n",
    "Other optional-but-helpful parameters for `gpt2.generate` and friends:\n",
    "\n",
    "*  **`length`**: Number of tokens to generate (default 1023, the maximum)\n",
    "* **`temperature`**: The higher the temperature, the crazier the text (default 0.7, recommended to keep between 0.7 and 1.0)\n",
    "* **`top_k`**: Limits the generated guesses to the top *k* guesses (default 0 which disables the behavior; if the generated output is super crazy, you may want to set `top_k=40`)\n",
    "* **`top_p`**: Nucleus sampling: limits the generated guesses to a cumulative probability. (gets good results on a dataset with `top_p=0.9`)\n",
    "* **`truncate`**: Truncates the input text until a given sequence, excluding that sequence (e.g. if `truncate='<|endoftext|>'`, the returned text will include everything before the first `<|endoftext|>`). It may be useful to combine this with a smaller `length` if the input texts are short.\n",
    "*  **`include_prefix`**: If using `truncate` and `include_prefix=False`, the specified `prefix` will not be included in the returned text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8DKMc0fiej4N",
    "outputId": "490a4648-d973-4675-cf9a-7a48c16fd736"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LORD FITZWATER:\n",
      "By heaven, I will not stand by while thy words are bandied about.\n",
      "\n",
      "RICHARD:\n",
      "Tyrannical times make good the sore; and\n",
      "thy old quarrel oft again becomes a joy.\n",
      "\n",
      "WARWICK:\n",
      "So will I no longer stand by while he prove a fool.\n",
      "\n",
      "KING RICHARD III:\n",
      "Now Joan's a torch to keep on the king;\n",
      "And his heir his mother's flame.\n",
      "\n",
      "WARWICK:\n",
      "Nay, my eyes will soon wither and die out;\n",
      "For I will be the man, as the flower is the fruit.\n",
      "\n",
      "KING RICHARD III:\n",
      "The more fool you by so much, the more light you allow.\n",
      "\n",
      "RICHARD:\n",
      "I am too heavy a sleeper to rest my meaning;\n",
      "But by the heavy fancy of my state\n",
      "I have lighten'd the minstrels by soaring high.\n",
      "\n",
      "KING RICHARD III:\n",
      "Ay, but I bethink me of no other but this:\n",
      "Come, let's away; the tediousness end.\n",
      "\n",
      "RICHARD:\n",
      "How now! what news with you?\n",
      "\n",
      "====================\n",
      "LORD ROSS:\n",
      "Yes, and by many, many\n",
      "And many more, many, many;\n",
      "And where I seem to stand, you may say,\n",
      "My stand, or your bosom is changed,\n",
      "My lord, my substitute, my sovereign.\n",
      "\n",
      "CLIFFORD:\n",
      "Then, good my lord,\n",
      "Look to the approach of night:\n",
      "Go, then, to the north-east; south-west, go.\n",
      "\n",
      "WARWICK:\n",
      "Get on, my lord; quickly I'll withdraw.\n",
      "\n",
      "YORK:\n",
      "The county of Lancaster shall be the field.\n",
      "\n",
      "MONTAGUE:\n",
      "And get ourself in, my lord; on the other hand,\n",
      "Go, with us, to the Duke of York's;\n",
      "there will I rest pat, and there awake I\n",
      "dine; that I may willingly accept and wear\n",
      "The regal crown.\n",
      "\n",
      "KING RICHARD III:\n",
      "Wine and ale? what's their brand?\n",
      "\n",
      "MONTAGUE:\n",
      "Theirs is their country's money: but they\n",
      "wear costly regalia; and we, being so rich\n",
      "in ale and straw, neither in men's nor women's,\n",
      "T\n",
      "====================\n",
      "LORD STANLEY:\n",
      "Is it thus that thou, Lord Hastings, art thus dealt,\n",
      "Under the title of a man?\n",
      "\n",
      "WARWICK:\n",
      "Why, am I thus dealt out to thee, Lord Hastings?\n",
      "\n",
      "KING RICHARD III:\n",
      "Thou art thus dealt out to me, Lord Hastings:\n",
      "Being so usurp'd, thou art but a man.\n",
      "But is it not plain sailing?\n",
      "\n",
      "WARWICK:\n",
      "Why, am I thus dealt out to thee, Lord Hastings?\n",
      "\n",
      "KING RICHARD III:\n",
      "Thou art thus dealt out to me, Lord Hastings:\n",
      "Being so usurp'd, thou art but a man.\n",
      "But is it not plain sailing?\n",
      "\n",
      "WARWICK:\n",
      "Why then, I puff my heart to the wind,\n",
      "And puff my chest to the blowing sea.\n",
      "\n",
      "KING RICHARD III:\n",
      "Why then, I speak aloud, I heart\n",
      "To thee, sweet Warwick, my life, thy death,\n",
      "Three fair English words and three fair hearts.\n",
      "\n",
      "WARWICK:\n",
      "What words shall I begin and end this merry dance?\n",
      "\n",
      "KING RICHARD III:\n",
      "As as as as\n",
      "====================\n",
      "LORD FITZWATER:\n",
      "love thy kinsman, for thyself\n",
      "I prize mine own perdition over thine.\n",
      "\n",
      "LORD FITZWATER:\n",
      "if thou match, and wilt prove mine own,\n",
      "Go chase after him, and he shall love thee well.\n",
      "\n",
      "LORD FITZWATER:\n",
      "if thou darest, I'll take him for my brother,\n",
      "Both love and truth, truth and falsehood.\n",
      "\n",
      "DUCHESS OF YORK:\n",
      "So thrive I in my profession as thou\n",
      "Can best advantage my skill! my brother\n",
      "Shalt be bring him to my cell, and there I\n",
      "Take him under my wing, to my profound environ\n",
      "Where serpents and marauding bats may perforce.\n",
      "\n",
      "DUCHESS OF YORK:\n",
      "How well I use this device! how well\n",
      "This prince may my care and my fortunes advance\n",
      "Upon my son! my dear-loved and respected queen and father\n",
      "And all the true friends of true York!\n",
      "What cares I for London, troth o' the morn?\n",
      "And shall I live in love with Crosby and Vaughan?\n",
      "Is love a thing sworn or\n",
      "====================\n",
      "LORD FITZWATER:\n",
      "Away with her!\n",
      "\n",
      "Second Murderer:\n",
      "How now! where have you been?\n",
      "\n",
      "Second Murderer:\n",
      "I have been sent for to the county.\n",
      "\n",
      "First Murderer:\n",
      "I pray you, do not call my master, now dead.\n",
      "\n",
      "Second Murderer:\n",
      "Now, Yorktown, I pray you, stay by me.\n",
      "\n",
      "First Murderer:\n",
      "You are a pair of robbers that will rob our store.\n",
      "\n",
      "Second Murderer:\n",
      "Why, Yorktown, I know thee well; and thou, knowing our need,\n",
      "Strives to be our stead broker.\n",
      "\n",
      "First Murderer:\n",
      "Well; what then? whither then comes the store to be ready?\n",
      "\n",
      "Second Murderer:\n",
      "Yea, then, which, Yorktown, as soon as now, we have.\n",
      "\n",
      "First Murderer:\n",
      "Strives you now, then arrives Yorktown, to rob our store?\n",
      "\n",
      "Second Murderer:\n",
      "Unhappily, I fear, for we will not be ransomed in that instance.\n",
      "\n",
      "First Murderer:\n",
      "Well, let it be known to Stanley that we\n",
      "====================\n"
     ]
    }
   ],
   "source": [
    "gpt2.generate(sess,\n",
    "              length=250,\n",
    "              temperature=0.7,\n",
    "              prefix=\"LORD\",\n",
    "              nsamples=5,\n",
    "              batch_size=5\n",
    "              )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zjjEN2Tafhl2"
   },
   "source": [
    "For bulk generation, you can generate a large amount of text to a file and sort out the samples locally on your computer. The next cell will generate a generated text file with a unique timestamp.\n",
    "\n",
    "You can rerun the cells as many times as you want for even more generated texts!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Fa6p6arifSL0"
   },
   "outputs": [],
   "source": [
    "gen_file = 'gpt2_gentext_{:%Y%m%d_%H%M%S}.txt'.format(datetime.utcnow())\n",
    "\n",
    "gpt2.generate_to_file(sess,\n",
    "                      destination_path=gen_file,\n",
    "                      length=500,\n",
    "                      temperature=0.7,\n",
    "                      nsamples=100,\n",
    "                      batch_size=20\n",
    "                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0-LRex8lfv1g"
   },
   "outputs": [],
   "source": [
    "# may have to run twice to get file to download\n",
    "files.download(gen_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QQAN3M6RT7Kj"
   },
   "source": [
    "## Generate Text From The Pretrained Model\n",
    "\n",
    "If you want to generate text from the pretrained model, not a finetuned model, pass `model_name` to `gpt2.load_gpt2()` and `gpt2.generate()`.\n",
    "\n",
    "This is currently the only way to generate text from the 774M or 1558M models with this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 158
    },
    "id": "hsUd_jHgUZnD",
    "outputId": "4e0c8a3f-3527-41c4-e3fe-3357f3f8f6c2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching checkpoint: 1.05Mit [00:00, 354Mit/s]                                                      \n",
      "Fetching encoder.json: 1.05Mit [00:00, 131Mit/s]                                                    \n",
      "Fetching hparams.json: 1.05Mit [00:00, 279Mit/s]                                                    \n",
      "Fetching model.ckpt.data-00000-of-00001: 3.10Git [00:23, 131Mit/s]                                  \n",
      "Fetching model.ckpt.index: 1.05Mit [00:00, 380Mit/s]                                                \n",
      "Fetching model.ckpt.meta: 2.10Mit [00:00, 226Mit/s]                                                 \n",
      "Fetching vocab.bpe: 1.05Mit [00:00, 199Mit/s]                                                       \n"
     ]
    }
   ],
   "source": [
    "model_name = \"774M\"\n",
    "\n",
    "gpt2.download_gpt2(model_name=model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 124
    },
    "id": "BAe4NpKNUj2C",
    "outputId": "b09bfe1d-2ff8-4b8a-fffb-273d28d5d4ae"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0828 18:37:58.571830 139905369159552 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pretrained model models/774M/model.ckpt\n"
     ]
    }
   ],
   "source": [
    "sess = gpt2.start_tf_sess()\n",
    "\n",
    "gpt2.load_gpt2(sess, model_name=model_name)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of Train a GPT-2 Text-Generating Model w/ GPU",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
